# -*- coding: utf-8 -*-
"""stockmarket_apple.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/dearbhupi/7853bc52a68d7ed363f0002fa1418433/stockmarket_apple.ipynb

#stock market
description : this program is an artificial recurrent neural network called Long Short Term Memory (LSTM) to predict the closing stock price of a corporation (Apple Inc.) using the last 10 years stock price
"""

#import library
import math
import pandas_datareader as web
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
print("all library imported successfully")

#get the stock quote
df = web.DataReader('AAPL', data_source='yahoo', start = '2012-01-01', end = '2019-12-17')
df
#df.head()
#df.tail()

df.shape

#visualize the closing price history
plt.figure(figsize=(16, 8))
plt.title("Apple Stock Market Report")
plt.plot(df['Close'])      #this close is close price of column 5 of the data we can change to high also
plt.xlabel ('Timeline', fontsize = 18)
plt.ylabel ('Close Price USD ($)', fontsize = 18)
plt.show()

#create a new dataframe with only the 'Close column'
data = df.filter(['Close'])
#convert the dataframe to a numpy array
dataset = data.values
#Get teh number of row to train the model one
training_data_len = math.ceil(len(dataset)* 0.8) #math.ceil to round up teh data and 0.8 will give 80% of value
training_data_len

#Scale the data, its always good practice to preprossing of normalization of data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)
scaled_data

#creating the training data set
#create the scaled training data set
train_data = scaled_data[0:training_data_len , :] #[start: end: all the column:]
#split the data into x_train and y_train data set
x_train = []
y_train = []
for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i,0])
    if i<=61:
        print(x_train)
        print(y_train)
        print()

#Convert the x_train and y_train to numpy array
x_train, y_train = np.array(x_train), np.array(y_train)

print(x_train.shape)
print(y_train.shape)

# as we see the data is in two D assay but LSTM model need in 3 D so we need to reshape
#Reshape the data why we need it because LSTM model need 
#x_train = np.reshape(x_train, (2075, 60, 1)) # number of row (sampel), number of colum (time) and 1 is closeing data
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_train.shape

#Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences= True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

#compile the model
model.compile(optimizer='adam', loss= 'mean_squared_error')

model.fit(x_train, y_train, batch_size=1, epochs=1)

#creating a testing data set
#create a new array containing scaled value from index 1543 to 200
test_data = scaled_data[training_data_len -60: , :]
x_test = []
y_test = dataset[training_data_len, :]
for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

#convert data to numpy array
x_test = np.array(x_test)

#reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

#Get the model prediction
prediction = model.predict(x_test)
prediction = scaler.inverse_transform(prediction)

#evaluvate the model
#RMSE is the root mean square error is the best way to check 
RMSE = np.sqrt(np.mean(prediction -y_test)**2)
RMSE

#plot the data
train = data[0:training_data_len]
valid = data[training_data_len:]
valid['Prediction'] = prediction
#visulaize the data
plt.figure(figsize=(16, 8))
plt.title("Model prediction (APPL)")

plt.xlabel ('Date', fontsize = 18)
plt.ylabel ('Close Price USD ($)', fontsize = 18)
plt.plot(train['Close']) 
plt.plot(valid[['Close', 'Prediction']])
plt.legend(['Train', 'Val', 'Prediction'], loc='lower right')
plt.show()

#show the valid and predicted prices
valid

#get the quote
apple_quote = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end = '2019-12-17')
#Create a new dataframe
new_df = apple_quote.filter(['Close'])
#get the last 60 day closing price values and convert to the dataframe to the array
last_60_days = new_df[-60:].values
#Scale the data to be value between 0 and 1
last_60_days_scaled = scaler.transform(last_60_days)
x_test = []
x_test.append(last_60_days_scaled)
#conver data to numpy array
x_test = np.array(x_test)
#reshpe the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
#get the predicted scaled price
pred_price = model.predict(x_test)
#undo the scaling
pred_price = scaler.inverse_transform(pred_price)
print(pred_price)

#get the quote
apple_quote_2 = web.DataReader('AAPL', data_source='yahoo', start='2019-12-17', end = '2019-12-17')
print(apple_quote_2['Close'])